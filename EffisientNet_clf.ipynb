{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "- [x] load data ~ 30 min\n",
    "- [x] Make prediction ~ 30 min\n",
    "- [x] Train model ~ 10 min\n",
    "    - [x] Fix model ~ 40 min\n",
    "- [x] Submit work ~ 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Global variables\n",
    "'''\n",
    "FOLDS = 5\n",
    "EPOCHS = 10\n",
    "batch_size = 512\n",
    "\n",
    "img_size = 44 # square\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation \n",
    "Preparing files paths,  \n",
    "Remap and translate to numbers our target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "path_20 = data_path + '/2020/128x128'\n",
    "path_19 = data_path + '/2019/128x128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19 = pd.read_csv(path_19 + '/train.csv')\n",
    "df_20 = pd.read_csv(path_20 + '/train.csv')\n",
    "\n",
    "df_20_test = pd.read_csv(path_20 + '/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_19 = df_19[['image_name', 'diagnosis']]\n",
    "# df_20 = df_20[['image_name', 'diagnosis']]\n",
    "\n",
    "df_19 = df_19[['image_name', 'target']]\n",
    "df_20 = df_20[['image_name', 'target']]\n",
    "df_20_test = df_20_test[['image_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing files paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19['image_name'] = [path_19+'/train/'+name+'.jpg' for name in df_19['image_name']]\n",
    "df_20['image_name'] = [path_20+'/train/'+name+'.jpg' for name in df_20['image_name']]\n",
    "\n",
    "df_20_test['image_name'] = [path_20+'/test/'+name+'.jpg' for name in df_20_test['image_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mega_df = df_19.append(df_20)\n",
    "total_targets = np.unique(np.append(df_19['target'].unique(), df_20['target'].unique()))\n",
    "stats = {l:(mega_df['target'] == l).sum() for l in mega_df['target'].unique()}\n",
    "\n",
    "plt.bar(total_targets, [v for _,v in stats.items()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISIC_DS(Dataset):\n",
    "    def __init__(self, df:pd.DataFrame, transform=None, isTest=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.isTest = isTest\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.isTest: return self._get_test_item(idx)\n",
    "            \n",
    "        path, target = self.df.iloc[idx]\n",
    "        \n",
    "        img = Image.open(path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def _get_test_item(self, idx):\n",
    "        path = self.df.iloc[idx][0]\n",
    "        \n",
    "        img = Image.open(path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {'train': T.Compose([\n",
    "    T.Resize(img_size),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]),\n",
    "            \n",
    "             'val':T.Compose([\n",
    "    T.Resize(img_size),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(df, train_idx, val_idx, bs=batch_size, t=transform, test_df=df_20_test):\n",
    "    loaders = {'train':None, 'val':None, 'test':None}\n",
    "    \n",
    "    loaders['train'] = DataLoader(ISIC_DS(df.iloc[train_idx], t['train']), bs, num_workers=12)\n",
    "    loaders['val']   = DataLoader(ISIC_DS(df.iloc[val_idx], t['val']), bs, num_workers=12)\n",
    "    loaders['test']  = DataLoader(ISIC_DS(test_df, t['val'], isTest=True), bs, num_workers=12)\n",
    "    \n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name, num_classes=2, device=device, sigmoid=True):\n",
    "    if name == 'b0':\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=num_classes)\n",
    "    elif name == 'b1':\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b1', num_classes=num_classes)\n",
    "       \n",
    "    if sigmoid:\n",
    "        # Model reshaping\n",
    "        in_features = model._fc.in_features\n",
    "        out_features = model._fc.out_features\n",
    "\n",
    "        model._fc = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_to_list(predictions):\n",
    "    # make probabilities from predictions\n",
    "    final = []\n",
    "    for pred in predictions:\n",
    "        prob, index = torch.max(pred, 1)\n",
    "        prob[index == 0] = 1 - prob[index == 0]\n",
    "        final += prob.tolist()\n",
    "    return final\n",
    "    \n",
    "def get_test_predictions(loader, prefix=''):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    for batch_x in loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        output = model(batch_x)\n",
    "\n",
    "        predictions.append(output.detach().cpu())\n",
    "        \n",
    "    final = preds_to_list(predictions)\n",
    "        \n",
    "    final_submission = pd.read_csv(path_20 + '/sample_submission.csv')\n",
    "    final_submission['target'] = final\n",
    "    final_submission.to_csv(f'outputs/oof_test_{prefix}.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        # set model to train mode\n",
    "        model.train()\n",
    "        # make predictions\n",
    "        yhat = model(x)\n",
    "        # computes loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # computes gradients\n",
    "        loss.backward()\n",
    "        # updats parameters and zeroes gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return yhat, loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_step(model, loss_fn):\n",
    "    def val_step(x, y):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x)\n",
    "            val_loss = loss_fn(yhat, y)\n",
    "\n",
    "            return val_loss.item()\n",
    "    return val_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_loop(train_step, val_step, loaders, epochs=EPOCHS):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = []\n",
    "        running_vloss= []\n",
    "        \n",
    "        running_yhat = []\n",
    "        running_y = []\n",
    "        \n",
    "        for batch_x, batch_y in loaders['train']:\n",
    "            batch_x = batch_x.to(device) \n",
    "            batch_y = batch_y.to(device) \n",
    "\n",
    "            yhat, loss = train_step(batch_x, batch_y)\n",
    "            running_loss.append(loss)\n",
    "            running_yhat.append(yhat.detach().cpu())\n",
    "            running_y += batch_y.detach().cpu().tolist()\n",
    "\n",
    "        for batch_x, batch_y in loaders['val']:\n",
    "            batch_x = batch_x.to(device) \n",
    "            batch_y = batch_y.to(device) \n",
    "            \n",
    "            vloss = val_step(batch_x, batch_y)\n",
    "            running_vloss.append(vloss)\n",
    "            \n",
    "        # Compute auc score\n",
    "        running_yhat = preds_to_list(running_yhat) \n",
    "        auc_score = roc_auc_score(running_y, running_yhat) \n",
    "  \n",
    "        print('[{}/{}] loss: {:.3f} auc: {:.3f}'\n",
    "              .format(epoch+1, epochs, np.mean(running_loss), auc_score))\n",
    "    return np.mean(running_loss), auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss_auc(loss, auc, fold, m_name=''):\n",
    "    file_name = 'outputs/models_oof_info.csv'\n",
    "    \n",
    "    head=['model_name', 'fold', 'loss', 'auc']\n",
    "\n",
    "    df = pd.DataFrame(columns=head)\n",
    "\n",
    "    new_row = dict(zip(head, [m_name, fold, loss, auc]))\n",
    "\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    if os.path.exists(file_name):\n",
    "        df.to_csv(file_name, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(file_name, index=False)\n",
    "        \n",
    "def save_val_preds(loader, prefix=''):\n",
    "    file_name = f'outputs/oof_val_{prefix}.csv'\n",
    "    \n",
    "    oof_preds = []\n",
    "    oof_y = []\n",
    "    \n",
    "    for batch_x, y in loader:\n",
    "        batch_x = batch_x.to(device)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            yhat = model(batch_x)\n",
    "            \n",
    "            oof_preds.append(yhat.detach().cpu())\n",
    "            oof_y += y.tolist()\n",
    "            \n",
    "    oof_preds = preds_to_list(oof_preds)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['y_true'] = oof_y\n",
    "    df['y_pred'] = oof_preds\n",
    "    df.to_csv(file_name, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD: 0\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "[1/3] loss: 0.705 auc: 0.499\n",
      "[2/3] loss: 0.686 auc: 0.498\n",
      "[3/3] loss: 0.669 auc: 0.499\n",
      "FOLD: 1\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "[1/3] loss: 0.683 auc: 0.548\n",
      "[2/3] loss: 0.666 auc: 0.539\n",
      "[3/3] loss: 0.652 auc: 0.527\n",
      "FOLD: 2\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "[1/3] loss: 0.700 auc: 0.519\n",
      "[2/3] loss: 0.681 auc: 0.530\n",
      "[3/3] loss: 0.664 auc: 0.522\n",
      "FOLD: 3\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "[1/3] loss: 0.696 auc: 0.507\n",
      "[2/3] loss: 0.678 auc: 0.519\n",
      "[3/3] loss: 0.662 auc: 0.519\n",
      "FOLD: 4\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "[1/3] loss: 0.670 auc: 0.499\n",
      "[2/3] loss: 0.654 auc: 0.506\n",
      "[3/3] loss: 0.641 auc: 0.499\n"
     ]
    }
   ],
   "source": [
    "##### K-fold cross validation\n",
    "skf = KFold(n_splits=FOLDS, shuffle=True, random_state=95)\n",
    "total_idx = np.arange(mega_df.shape[0])\n",
    "\n",
    "model_name = 'b1'\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(total_idx)):\n",
    "    print(f'FOLD: {fold}')\n",
    "    # Set data\n",
    "    loaders = get_loaders(mega_df, train_idx, val_idx)\n",
    "    \n",
    "    # Set model\n",
    "    model = get_model(model_name, device=device)\n",
    "\n",
    "    # Preapering to training\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "    train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "    # Set train/val step\n",
    "    train_step = make_train_step(model, loss_fn, optimizer)\n",
    "    val_step = make_val_step(model, loss_fn)\n",
    "    \n",
    "    # Train loop\n",
    "    loss, auc = train_loop(train_step, val_step, loaders, epochs=3)\n",
    "    \n",
    "    # Prediction loop\n",
    "    get_test_predictions(loaders['test'], prefix=model_name+'_'+str(fold))\n",
    "    save_val_preds(loaders['val'], prefix=model_name+'_'+str(fold))\n",
    "#     save_loss_auc(loss, auc, fold, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "# get total oof predictions\n",
    "oof = {'b0':pd.DataFrame(), 'b1':pd.DataFrame()}\n",
    "\n",
    "for i in range(5):\n",
    "    oof['b0'] = pd.concat([oof['b0'], pd.read_csv(f'outputs/oof_val_b0_{i}.csv')], ignore_index=True)\n",
    "    oof['b1'] = pd.concat([oof['b1'], pd.read_csv(f'outputs/oof_val_b1_{i}.csv')], ignore_index=True)\n",
    "\n",
    "for w in np.arange(0,1,0.01):\n",
    "    y_pred = w * oof['b0']['y_pred'].values + (1-w)*oof['b1']['y_pred'].values\n",
    "\n",
    "    auc = roc_auc_score(oof['b0']['y_true'], y_pred)\n",
    "\n",
    "    all_scores.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: 0.99, AUC: 0.483\n"
     ]
    }
   ],
   "source": [
    "max_idx = np.argmax(all_scores)\n",
    "max_w = np.arange(0, 1, 0.01)[max_idx]\n",
    "\n",
    "print('Weight: {}, AUC: {:.3f}'\n",
    "      .format(max_w, all_scores[max_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_test = {'b0':[], 'b1':[]}\n",
    "\n",
    "for i in range(5):\n",
    "    oof_test['b0'] += [pd.read_csv(f'outputs/oof_test_b0_{i}.csv')['target'].values] \n",
    "    oof_test['b1'] += [pd.read_csv(f'outputs/oof_test_b1_{i}.csv')['target'].values] \n",
    "\n",
    "oof_test['b0'] = np.mean(oof_test['b0'], 0)\n",
    "oof_test['b1'] = np.mean(oof_test['b1'], 0)\n",
    "\n",
    "\n",
    "y_pred = max_w * oof_test['b0'] + (1-max_w)*oof_test['b1']['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10982,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(preds):\n",
    "    import seaborn as sns\n",
    "    fig, ax = plt.subplots(figsize=(6,3), dpi=120)\n",
    "    sns.distplot(preds, hist_kws={\n",
    "                     'rwidth': 0.75,\n",
    "                     'edgecolor': 'black',\n",
    "                     'alpha': 0.3\n",
    "                 }, color='#1B9CC2')\n",
    "    ax.set_title('Final Predictions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = pd.read_csv(path_20 + '/sample_submission.csv')\n",
    "final_submission['target'] = final\n",
    "final_submission.to_csv('final_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
